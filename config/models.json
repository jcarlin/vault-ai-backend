{
  "models": [
    {
      "id": "qwen2.5-32b-awq",
      "name": "Qwen 2.5 32B (AWQ Quantized)",
      "parameters": "32B",
      "quantization": "AWQ 4-bit",
      "context_window": 32768,
      "vram_required_gb": 20,
      "description": "Best balance of capability and speed. Recommended for most use cases.",
      "path": "/opt/vault/models/qwen2.5-32b-awq",
      "type": "chat"
    },
    {
      "id": "llama-3.3-8b-q4",
      "name": "Llama 3.3 8B (4-bit)",
      "parameters": "8B",
      "quantization": "AWQ 4-bit",
      "context_window": 131072,
      "vram_required_gb": 6,
      "description": "Fast model for simple tasks. Lower capability but 4x faster.",
      "path": "/opt/vault/models/llama-3.3-8b-q4",
      "type": "chat"
    },
    {
      "id": "gemini-2.0-flash",
      "name": "Gemini 2.0 Flash",
      "parameters": "cloud",
      "context_window": 1048576,
      "description": "Google Gemini 2.0 Flash — fast, cloud-hosted model for demos and development.",
      "type": "chat"
    },
    {
      "id": "gemini-2.5-flash",
      "name": "Gemini 2.5 Flash",
      "parameters": "cloud",
      "context_window": 1048576,
      "description": "Google Gemini 2.5 Flash — latest generation, cloud-hosted.",
      "type": "chat"
    },
    {
      "id": "gemini-2.5-pro",
      "name": "Gemini 2.5 Pro",
      "parameters": "cloud",
      "context_window": 1048576,
      "description": "Google Gemini 2.5 Pro — highest capability cloud model.",
      "type": "chat"
    }
  ]
}
